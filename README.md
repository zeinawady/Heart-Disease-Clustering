# Clustering Heart Disease Patients

## ğŸ“Œ Project Overview
This project applies **unsupervised machine learning techniques** to cluster heart disease patients based on their medical records. The goal is to identify patient groups with similar health profiles, which could help doctors tailor treatments more effectively.

## ğŸ“‘ Table of Contents
- [Dataset Overview](#ğŸ“Š-dataset-overview)
- [Data Preprocessing](#ğŸ”§-data-preprocessing)
- [Clustering Techniques](#ğŸ”-clustering-techniques)
  - [K-Means Clustering](#1ï¸âƒ£-k-means-clustering)
  - [DBSCAN (Density-Based Clustering)](#2ï¸âƒ£-dbscan-density-based-clustering)
  - [Hierarchical Clustering](#3ï¸âƒ£-hierarchical-clustering)
  - [K-Medoids Clustering (PAM)](#4ï¸âƒ£-k-medoids-clustering-pam)
- [Feature Impact Analysis](#ğŸ“ˆ-feature-impact-analysis)
- [Clustering Method Comparison](#ğŸ“Š-clustering-method-comparison)

## ğŸ“Š Dataset Overview
- **Source:** Heart Disease Dataset  
- **Size:** 306 patients, 12 features  
- **Features:**  
  - **Numerical:** Age, Resting Blood Pressure (Trestbps), Cholesterol (Chol), Maximum Heart Rate (Thalach), ST Depression (Oldpeak), and Heart Rate Recovery (HRR - an engineered feature).  
  - **Categorical:** Slope (missing values imputed with mode).  

## ğŸ”§ Data Preprocessing
- **Cleaning:** Removed unnecessary columns, handled missing values, and eliminated duplicates.  
- **Feature Engineering:** Created **Heart Rate Recovery (HRR)** = Thalach - 70 for additional insights.  
- **Feature Scaling:** Standardized numerical features for better clustering performance.  

## ğŸ” Clustering Techniques
### 1ï¸âƒ£ K-Means Clustering
- **Optimal k:** 3 (determined via Elbow Method)  
- **Silhouette Score:** 0.241  
- **Visualization:** Elbow Method plot, K-Means clusters
<p>
  <img src="images/K-Means.png" alt="K-Means Clustering" width="60%"/>
</p>

### 2ï¸âƒ£ DBSCAN (Density-Based Clustering)
- **Parameters:** Îµ = 0.8, minPts = 5  
- **Silhouette Score:** 0.029 (excluding noise points)  
- **Visualization:** DBSCAN cluster visualization
<p>
  <img src="images/DBSCAN.png" alt="DBSCAN Clustering" width="60%"/>
</p>

### 3ï¸âƒ£ Hierarchical Clustering
- **Linkage Method:** Ward's Method  
- **Optimal Clusters:** 3 (determined via dendrogram)  
- **Silhouette Score:** 0.216  
- **Visualization:**
  - Dendrogram Plot
    <p>
      <img src="images/Dendrogram.png" alt="Dendrogram Plot" width="60%"/>
    </p>

  - Hierarchical clustering visualization
    <p>
      <img src="images/Hierarchical.png" alt="Hierarchical clustering" width="60%"/>
    </p>

### 4ï¸âƒ£ K-Medoids Clustering (PAM)
- **Clusters:** 3  
- **Silhouette Score:** 0.162  
- **Visualization:** K-Medoids cluster visualization
<p>
  <img src="images/K-Medoids.png" alt="K-Medoids cluster" width="60%"/>
</p>

## ğŸ“ˆ Feature Impact Analysis
- Tested clustering with reduced features: **Age, Trestbps, Chol, Thalach, HRR**.  
- **Silhouette Score for reduced set:** 0.239 (slightly lower, but improved interpretability).  

## ğŸ“Š Clustering Method Comparison

| Algorithm   | Silhouette Score | Observations |
|------------|----------------|-------------|
| **K-Means**  | 0.241 | Stable clusters with high silhouette score |
| **DBSCAN**   | 0.029 | Effective for non-spherical clusters but sensitive to Îµ |
| **Hierarchical** | 0.216 | Well-separated clusters but computationally intensive |
| **K-Medoids** | 0.162 | Robust to noise and outliers |

## ğŸ“Œ Conclusion
- **K-Means and Hierarchical Clustering** provided the best cluster separation.  
- The engineered **HRR feature** improved clustering effectiveness.  
- Feature reduction simplified interpretation with minimal performance loss.  


